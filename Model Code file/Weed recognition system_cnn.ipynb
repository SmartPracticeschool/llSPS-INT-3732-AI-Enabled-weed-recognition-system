{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #to initialize models\n",
    "from tensorflow.keras.layers import Dense #adding layers\n",
    "from tensorflow.keras.layers import Conv2D #convolution layer\n",
    "from tensorflow.keras.layers import MaxPool2D #maxpooling\n",
    "from tensorflow.keras.layers import Flatten \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " model.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "#1st parameter in conv2D = no. of Feature detectors\n",
    "#2nd &3rd parmater = size of feat. Detect.\n",
    "#4th parameter = Expected input image shape\n",
    "#5th parameter =Activation fnctn.\n",
    "# 64,64,3 for rgb and 64,64,1 for grey scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten()) #convert n to 1-dim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=128,activation='relu',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               409728    \n",
      "=================================================================\n",
      "Total params: 410,624\n",
      "Trainable params: 410,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=3,activation='softmax',kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 21, 21, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 411,011\n",
      "Trainable params: 411,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1./255,shear_range=0.2,horizontal_flip=True,zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 309 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train=train_datagen.flow_from_directory(r'C:\\Users\\PC\\Internship\\Weed dataset\\TRAIN',target_size=(64,64),batch_size=16,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test=train_datagen.flow_from_directory(r'C:\\Users\\PC\\Internship\\Weed dataset\\TEST',target_size=(64,64),batch_size=16,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more than 2 category then class mode= categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hedge bindweed train': 0, 'grass train': 1, 'stinging nettle train': 2}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "309/309 [==============================] - 44s 144ms/step - loss: 0.4002 - accuracy: 0.8375 - val_loss: 0.2892 - val_accuracy: 0.8659\n",
      "Epoch 2/10\n",
      "309/309 [==============================] - 50s 163ms/step - loss: 0.1963 - accuracy: 0.9297 - val_loss: 0.2303 - val_accuracy: 0.8841\n",
      "Epoch 3/10\n",
      "309/309 [==============================] - 52s 167ms/step - loss: 0.1339 - accuracy: 0.9557 - val_loss: 0.2621 - val_accuracy: 0.8893\n",
      "Epoch 4/10\n",
      "309/309 [==============================] - 50s 163ms/step - loss: 0.0865 - accuracy: 0.9669 - val_loss: 0.2487 - val_accuracy: 0.8971\n",
      "Epoch 5/10\n",
      "309/309 [==============================] - 51s 165ms/step - loss: 0.0536 - accuracy: 0.9820 - val_loss: 0.4057 - val_accuracy: 0.8659\n",
      "Epoch 6/10\n",
      "309/309 [==============================] - 51s 164ms/step - loss: 0.0376 - accuracy: 0.9887 - val_loss: 0.4578 - val_accuracy: 0.8633\n",
      "Epoch 7/10\n",
      "309/309 [==============================] - 54s 174ms/step - loss: 0.0340 - accuracy: 0.9899 - val_loss: 0.4246 - val_accuracy: 0.8780\n",
      "Epoch 8/10\n",
      "309/309 [==============================] - 51s 164ms/step - loss: 0.0152 - accuracy: 0.9962 - val_loss: 0.6091 - val_accuracy: 0.8720\n",
      "Epoch 9/10\n",
      "309/309 [==============================] - 50s 162ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 0.4163 - val_accuracy: 0.9005\n",
      "Epoch 10/10\n",
      "309/309 [==============================] - 51s 164ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.5368 - val_accuracy: 0.8651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bb53d2db48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,steps_per_epoch=309,epochs=10,validation_data=x_test,validation_steps=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1677381e-05 6.8701494e-01 3.1296337e-01]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "model=load_model('weed.h5')\n",
    "from skimage.transform import resize\n",
    "\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img= resize(frame,(64,64))\n",
    "        #print(\"dim\",img)\n",
    "        img=np.expand_dims(img,axis=0)\n",
    "         #print(\"dim2\",img)\n",
    "        if(np.max(img)>1):\n",
    "            img= img/255.0\n",
    "            \n",
    "        prediction=model.predict(img)\n",
    "        print(prediction)\n",
    "        print(model.predict_classes(img))\n",
    "    except AttributeError:\n",
    "        print(\"Shape Not found\")\n",
    "        \n",
    "frame=cv2.imread(r'C:\\Users\\PC\\Internship\\Weed dataset\\TEST\\grass test\\148.jpg')\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.8653144e-01 1.3454662e-02 1.3840561e-05]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'C:\\Users\\PC\\Internship\\Weed dataset\\TEST\\Hedge bindweed test\\ii.jpg')\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.18841834e-01 1.16510205e-06 8.81157041e-01]]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(r'C:\\Users\\PC\\Internship\\Weed dataset\\TEST\\stinging nettle test\\2.jpg')\n",
    "data=detect(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
